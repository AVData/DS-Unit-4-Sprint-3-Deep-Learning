{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shape of data is imporotant!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart.\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.gutenberg.org/files/100/100-0.txt\n",
      "5783552/5777367 [==============================] - 4s 1us/step\n",
      "corpus length: 5573152\n"
     ]
    }
   ],
   "source": [
    "path = get_file('100-0.txt',origin='https://www.gutenberg.org/files/100/100-0.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' project gutenberg’s the complete works of william shakespeare, by william shakespeare  this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org.  if you are not located in the united states, you’ll have to check the laws of the country where you are located before using this ebook.   title: the complete works of william shakespeare  author: william shakespeare  release date: january 1994 [ebook #100] last updated: november 7, 2019  language: english  character set encoding: utf-8  *** start of this project gutenberg ebook the complete works of william shakespeare ***     the complete works of william shakespeare    by william shakespeare           contents                   the sonnets                 all’s well that ends well                 the tragedy of antony and cleopatra                 as you like it                 the comedy of errors                 the tragedy of coriolanus                 cymbeline                 the tragedy of hamlet, prince of denmark                 the first part of king henry the fourth                 the second part of king henry the fourth                 the life of king henry the fifth                 the first part of henry the sixth                 the second part of king henry the sixth                 the third part of king henry the sixth                 king henry the eighth                 king john                 the tragedy of julius caesar                 the tragedy of king lear                 love’s labour’s lost                 the tragedy of macbeth                 measure for measure                 the merchant of venice                 the merry wives of windsor                 a midsummer night’s dream                 much ado about nothing                 the tragedy of othello, moor of venice                 pericles, prince of tyre                 king richard the second                 king richard the third                 the tragedy of romeo and juliet                 the taming of the shrew                 the tempest                 the life of timon of athens                 the tragedy of titus andronicus                 the history of troilus and cressida                 twelfth night; or, what you will                 the two gentlemen of verona                 the two noble kinsmen                 the winter’s tale                 a lover’s complaint                 the passionate pilgrim                 the phoenix and the turtle                 the rape of lucrece                 venus and adonis       the sonnets                      1  from fairest creatures we desire increase, that thereby beauty’s rose might never die, but as the riper should by time decease, his tender heir might bear his memory: but thou contracted to thine own bright eyes, feed’st thy light’s flame with self-substantial fuel, making a famine where abundance lies, thy self thy foe, to thy sweet self too cruel: thou that art now the world’s fresh ornament, and only herald to the gaudy spring, within thine own bud buriest thy content, and, tender churl, mak’st waste in niggarding:   pity the world, or else this glutton be,   to eat the world’s due, by the grave and thee.                       2  when forty winters shall besiege thy brow, and dig deep trenches in thy beauty’s field, thy youth’s proud livery so gazed on now, will be a tattered weed of small worth held: then being asked, where all thy beauty lies, where all the treasure of thy lusty days; to say, within thine own deep sunken eyes, were an all-eating shame, and thriftless praise. how much more praise deserv’d thy beauty’s use, if thou couldst answer ‘this fair child of mine shall sum my count, and make my old excuse,’ proving his beauty by succession thine.   this were to be'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clearning the text a bit\n",
    "\n",
    "text = text.replace(\"\\n\", ' ')\n",
    "text = text.replace(\"\\ufeff\", '')\n",
    "text[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my aim is to train isolate the works so that the model learns specifically from \n",
    "# shakespear, and not legal, nor gutenberg related text\n",
    "\n",
    "# finding the begining of the actual works\n",
    "text.index('shakespear ***')\n",
    "\n",
    "text = text[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the end of the shakespears actual works\n",
    "\n",
    "text.index('* conntent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he drops the stalk, and in the breach appears   green-dropping sap, which she compares to tears.  “poor flower,” quoth she, “this was thy father’s guise, sweet issue of a more sweet-smelling sire, for every little grief to wet his eyes, to grow unto himself was his desire,                1180   and so ’tis thine; but know, it is as good   to wither in my breast as in his blood.  “here was thy father’s bed, here in my breast; thou art the next of blood, and ’tis thy right:     1184 lo in this hollow cradle take thy rest, my throbbing heart shall rock thee day and night:   there shall not be one minute in an hour   wherein i will not kiss my sweet love’s flower.”  thus weary of the world, away she hies,             1189 and yokes her silver doves; by whose swift aid their mistress mounted through the empty skies, in her light chariot quickly is convey’d;           1192   holding their course to paphos, where their queen   means to immure herself and not be seen.       finis              '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing tail end\n",
    "\n",
    "text = text[:5549291]\n",
    "text[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 72\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  1109851\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_indices[c] for c in text]\n",
    "\n",
    "sequences = []\n",
    "next_char = []\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "\n",
    "print('sequences: ', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49,\n",
       " 37,\n",
       " 34,\n",
       " 1,\n",
       " 48,\n",
       " 44,\n",
       " 43,\n",
       " 43,\n",
       " 34,\n",
       " 49,\n",
       " 48,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 35,\n",
       " 47,\n",
       " 44,\n",
       " 42]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creatgin x & y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)))\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i, t, char] = 1\n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1109851, 40, 72)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1109851, 72)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_pred / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1\n",
    "        pred = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = indices_chars[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "    \n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S2-NN (Python3)",
   "language": "python",
   "name": "u4-s1-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
